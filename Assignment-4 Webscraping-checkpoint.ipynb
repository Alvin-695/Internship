{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "729fad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905a76e3",
   "metadata": {},
   "source": [
    "##### 1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A) Rank B) NameC) ArtistD) Upload dateE) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aed51200",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki=webdriver.Chrome()\n",
    "wiki.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos') # Initializing the WebDriver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c8b7bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>14.09</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.38</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Johny Johny Yes Papa\"[17]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>6.87</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Bath Song\"[18]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.62</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Shape of You\"[19]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.20</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>6.17</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>5.88</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Phonics Song with Two Words\"[28]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>5.70</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Uptown Funk\"[29]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.15</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Learning Colors ‚Äì Colorful Eggs on a Farm\"[30]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>5.07</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>5.05</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Masha and the Bear ‚Äì Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.58</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>4.55</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.34</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.97</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>3.96</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"Roar\"[42]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.96</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"Lakdi Ki Kathi\"[43]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.91</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[44]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.85</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\"Sorry\"[45]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.77</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\"Thinking Out Loud\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.73</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.73</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\"Shree Hanuman Chalisa\"[48]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>3.69</td>\n",
       "      <td>May 10, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"Dark Horse\"[49]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.67</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\"Perfect\"[50]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.67</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"Let Her Go\"[51]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.61</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"Faded\"[52]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.59</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"Girls Like You\"[53]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.56</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"Lean On\"[54]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>3.55</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Video Name  \\\n",
       "Rank                                                    \n",
       "0                               \"Baby Shark Dance\"[6]   \n",
       "1                                      \"Despacito\"[9]   \n",
       "2                          \"Johny Johny Yes Papa\"[17]   \n",
       "3                                     \"Bath Song\"[18]   \n",
       "4                                  \"Shape of You\"[19]   \n",
       "5                                 \"See You Again\"[22]   \n",
       "6                             \"Wheels on the Bus\"[27]   \n",
       "7                   \"Phonics Song with Two Words\"[28]   \n",
       "8                                   \"Uptown Funk\"[29]   \n",
       "9     \"Learning Colors ‚Äì Colorful Eggs on a Farm\"[30]   \n",
       "10                                \"Gangnam Style\"[31]   \n",
       "11     \"Masha and the Bear ‚Äì Recipe for Disaster\"[36]   \n",
       "12                               \"Dame Tu Cosita\"[37]   \n",
       "13                                       \"Axel F\"[38]   \n",
       "14                                        \"Sugar\"[39]   \n",
       "15                               \"Counting Stars\"[40]   \n",
       "16                          \"Baa Baa Black Sheep\"[41]   \n",
       "17                                         \"Roar\"[42]   \n",
       "18                               \"Lakdi Ki Kathi\"[43]   \n",
       "19             \"Waka Waka (This Time for Africa)\"[44]   \n",
       "20                                        \"Sorry\"[45]   \n",
       "21                            \"Thinking Out Loud\"[46]   \n",
       "22            \"Humpty the train on a fruits ride\"[47]   \n",
       "23                        \"Shree Hanuman Chalisa\"[48]   \n",
       "24                                   \"Dark Horse\"[49]   \n",
       "25                                      \"Perfect\"[50]   \n",
       "26                                   \"Let Her Go\"[51]   \n",
       "27                                        \"Faded\"[52]   \n",
       "28                               \"Girls Like You\"[53]   \n",
       "29                                      \"Lean On\"[54]   \n",
       "\n",
       "                                                 Artist  Views  \\\n",
       "Rank                                                             \n",
       "0           Pinkfong Baby Shark - Kids' Songs & Stories  14.09   \n",
       "1                                            Luis Fonsi   8.38   \n",
       "2     LooLoo Kids - Nursery Rhymes and Children's Songs   6.87   \n",
       "3                            Cocomelon - Nursery Rhymes   6.62   \n",
       "4                                            Ed Sheeran   6.20   \n",
       "5                                           Wiz Khalifa   6.17   \n",
       "6                            Cocomelon - Nursery Rhymes   5.88   \n",
       "7                 ChuChu TV Nursery Rhymes & Kids Songs   5.70   \n",
       "8                                           Mark Ronson   5.15   \n",
       "9                                           Miroshka TV   5.07   \n",
       "10                                                  Psy   5.05   \n",
       "11                                           Get Movies   4.58   \n",
       "12                                        Ultra Records   4.55   \n",
       "13                                           Crazy Frog   4.34   \n",
       "14                                             Maroon 5   4.00   \n",
       "15                                          OneRepublic   3.97   \n",
       "16                           Cocomelon - Nursery Rhymes   3.96   \n",
       "17                                           Katy Perry   3.96   \n",
       "18                                         Jingle Toons   3.91   \n",
       "19                                              Shakira   3.85   \n",
       "20                                        Justin Bieber   3.77   \n",
       "21                                           Ed Sheeran   3.73   \n",
       "22        Kiddiestv Hindi - Nursery Rhymes & Kids Songs   3.73   \n",
       "23                                T-Series Bhakti Sagar   3.69   \n",
       "24                                           Katy Perry   3.67   \n",
       "25                                           Ed Sheeran   3.67   \n",
       "26                                            Passenger   3.61   \n",
       "27                                          Alan Walker   3.59   \n",
       "28                                             Maroon 5   3.56   \n",
       "29                                 Major Lazer Official   3.55   \n",
       "\n",
       "            Upload Date  \n",
       "Rank                     \n",
       "0         June 17, 2016  \n",
       "1      January 12, 2017  \n",
       "2       October 8, 2016  \n",
       "3           May 2, 2018  \n",
       "4      January 30, 2017  \n",
       "5         April 6, 2015  \n",
       "6          May 24, 2018  \n",
       "7         March 6, 2014  \n",
       "8     November 19, 2014  \n",
       "9     February 27, 2018  \n",
       "10        July 15, 2012  \n",
       "11     January 31, 2012  \n",
       "12        April 5, 2018  \n",
       "13        June 16, 2009  \n",
       "14     January 14, 2015  \n",
       "15         May 31, 2013  \n",
       "16        June 25, 2018  \n",
       "17    September 5, 2013  \n",
       "18        June 14, 2018  \n",
       "19         June 4, 2010  \n",
       "20     October 22, 2015  \n",
       "21      October 7, 2014  \n",
       "22     January 26, 2018  \n",
       "23         May 10, 2011  \n",
       "24    February 20, 2014  \n",
       "25     November 9, 2017  \n",
       "26        July 25, 2012  \n",
       "27     December 3, 2015  \n",
       "28         May 31, 2018  \n",
       "29       March 22, 2015  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video=[]\n",
    "Upload=[]\n",
    "Artist=[]\n",
    "Views=[]\n",
    "# Finding the table containing video details\n",
    "\n",
    "Vi=wiki.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers col3center col4right jquery-tablesorter\"][1]/tbody/tr/td[1]')\n",
    "for i in Vi:\n",
    "    Video.append(i.text)\n",
    "\n",
    "artist=wiki.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers col3center col4right jquery-tablesorter\"][1]/tbody/tr/td[2]')\n",
    "for i in artist:\n",
    "    Artist.append(i.text)\n",
    "\n",
    "views=wiki.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers col3center col4right jquery-tablesorter\"][1]/tbody/tr/td[3]')\n",
    "for i in views:\n",
    "        Views.append(i.text)\n",
    "\n",
    "upload_date=wiki.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers col3center col4right jquery-tablesorter\"][1]/tbody/tr/td[4]')\n",
    "for i in upload_date:\n",
    "        Upload.append(i.text)\n",
    "\n",
    "df_yt=pd.DataFrame({\"Video Name\":Video, \"Artist\":Artist, \"Views\":Views, \"Upload Date\":Upload})\n",
    "df_yt.index.name=\"Rank\"\n",
    "df_yt# Creating a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ae979",
   "metadata": {},
   "source": [
    "##### 2. Scrape the details team India‚Äôs international fixtures from bcci.tv. Url = https://www.bcci.tv/.You need to find following details:A) SeriesB) PlaceC) DateD) Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4d2ca54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcci=webdriver.Chrome()\n",
    "bcci.get(\"https://www.bcci.tv/\") # Initializing the WebDriver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7f8ff70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "select=bcci.find_element(By.XPATH,'/html/body/header/div[3]/div[2]/ul/div[1]/a[2]')\n",
    "select.click()# Clicking on the \"International\" link to reach the fixture page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "620ffa8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>JSCA International Stadium Complex,</td>\n",
       "      <td>23 FEBRUARY, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium,</td>\n",
       "      <td>7 MARCH, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>6 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>7 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>10 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>13 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>14 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Series  \\\n",
       "0  ENGLAND TOUR OF INDIA 2023-24   \n",
       "1  ENGLAND TOUR OF INDIA 2023-24   \n",
       "2    INDIA TOUR OF ZIMBABWE 2024   \n",
       "3    INDIA TOUR OF ZIMBABWE 2024   \n",
       "4    INDIA TOUR OF ZIMBABWE 2024   \n",
       "5    INDIA TOUR OF ZIMBABWE 2024   \n",
       "6    INDIA TOUR OF ZIMBABWE 2024   \n",
       "\n",
       "                                           Place               Date  \\\n",
       "0            JSCA International Stadium Complex,  23 FEBRUARY, 2024   \n",
       "1  Himachal Pradesh Cricket Association Stadium,      7 MARCH, 2024   \n",
       "2                            Harare Sports Club,       6 JULY, 2024   \n",
       "3                            Harare Sports Club,       7 JULY, 2024   \n",
       "4                            Harare Sports Club,      10 JULY, 2024   \n",
       "5                            Harare Sports Club,      13 JULY, 2024   \n",
       "6                            Harare Sports Club,      14 JULY, 2024   \n",
       "\n",
       "          Time  \n",
       "0  9:30 AM IST  \n",
       "1  9:30 AM IST  \n",
       "2  8:00 PM IST  \n",
       "3  8:00 PM IST  \n",
       "4  8:00 PM IST  \n",
       "5  8:00 PM IST  \n",
       "6  8:00 PM IST  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series=[]\n",
    "place=[] \n",
    "date=[]\n",
    "time=[]\n",
    "\n",
    "# Finding the fixture details\n",
    "\n",
    "s_t=bcci.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in s_t:\n",
    "    try:\n",
    "        series.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        series.append('-')\n",
    "\n",
    "p=bcci.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]')\n",
    "for i in p:\n",
    "    try:\n",
    "        place.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        place.append('-')\n",
    "\n",
    "d=bcci.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in d:\n",
    "    try:\n",
    "        date.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date.append('-')\n",
    "\n",
    "t=bcci.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in t:\n",
    "    try:\n",
    "        time.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        time.append('-')\n",
    "    \n",
    "df_India=pd.DataFrame({\"Series\":series, \"Place\":place, \"Date\":date, \"Time\":time})\n",
    "df_India# Creating a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5af7ac",
   "metadata": {},
   "source": [
    "##### 3. Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f8161154",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp=webdriver.Chrome()\n",
    "gdp.get('http://statisticstimes.com/') # Initializing the WebDriver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b608d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "eco=gdp.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "eco.click()\n",
    "eco_b=gdp.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "eco_b.click()# Navigate to the economy page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7972e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_b=gdp.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "st_b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "89d95638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP22-23</th>\n",
       "      <th>GSDP21-22</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>3,108,022</td>\n",
       "      <td>13.24%</td>\n",
       "      <td>417.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>2,257,575</td>\n",
       "      <td>1,974,532</td>\n",
       "      <td>8.41%</td>\n",
       "      <td>265.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,937,066</td>\n",
       "      <td>8.25%</td>\n",
       "      <td>259.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,413,620</td>\n",
       "      <td>1,218,193</td>\n",
       "      <td>5.19%</td>\n",
       "      <td>163.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>1,317,728</td>\n",
       "      <td>1,133,837</td>\n",
       "      <td>4.83%</td>\n",
       "      <td>152.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>932,470</td>\n",
       "      <td>3.97%</td>\n",
       "      <td>125.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>994,154</td>\n",
       "      <td>870,665</td>\n",
       "      <td>3.71%</td>\n",
       "      <td>116.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>751,396</td>\n",
       "      <td>650,302</td>\n",
       "      <td>2.77%</td>\n",
       "      <td>87.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>493,167</td>\n",
       "      <td>412,612</td>\n",
       "      <td>1.76%</td>\n",
       "      <td>55.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>393,722</td>\n",
       "      <td>358,863</td>\n",
       "      <td>1.53%</td>\n",
       "      <td>48.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir-UT</td>\n",
       "      <td>227,927</td>\n",
       "      <td>199,917</td>\n",
       "      <td>0.85%</td>\n",
       "      <td>26.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>-</td>\n",
       "      <td>82,604</td>\n",
       "      <td>0.35%</td>\n",
       "      <td>11.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>45,635</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>6.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>42,697</td>\n",
       "      <td>38,785</td>\n",
       "      <td>0.17%</td>\n",
       "      <td>5.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>-</td>\n",
       "      <td>36,594</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>4.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>31,913</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>10,371</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>1.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,690,525</td>\n",
       "      <td>13.24%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>2,036,748</td>\n",
       "      <td>1,782,121</td>\n",
       "      <td>8.77%</td>\n",
       "      <td>1,190,851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,700,504</td>\n",
       "      <td>8.37%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,259,527</td>\n",
       "      <td>1,084,845</td>\n",
       "      <td>5.34%</td>\n",
       "      <td>694,771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,187,082</td>\n",
       "      <td>1,024,205</td>\n",
       "      <td>5.04%</td>\n",
       "      <td>642,207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>822,970</td>\n",
       "      <td>4.05%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>885,308</td>\n",
       "      <td>779,197</td>\n",
       "      <td>3.83%</td>\n",
       "      <td>542,972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>15</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>691,888</td>\n",
       "      <td>587,900</td>\n",
       "      <td>2.89%</td>\n",
       "      <td>403,222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>427,147</td>\n",
       "      <td>363,161</td>\n",
       "      <td>1.79%</td>\n",
       "      <td>251,688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>360,689</td>\n",
       "      <td>325,830</td>\n",
       "      <td>1.60%</td>\n",
       "      <td>235,685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir-UT</td>\n",
       "      <td>185,489</td>\n",
       "      <td>162,644</td>\n",
       "      <td>0.80%</td>\n",
       "      <td>105,636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>-</td>\n",
       "      <td>73,973</td>\n",
       "      <td>0.36%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>40,573</td>\n",
       "      <td>0.20%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>37,925</td>\n",
       "      <td>34,441</td>\n",
       "      <td>0.17%</td>\n",
       "      <td>21,905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>29</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>31,669</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,859</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>9,209</td>\n",
       "      <td>0.05%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State  GSDP22-23  GSDP21-22   Share  \\\n",
       "0     1                Maharashtra          -  3,108,022  13.24%   \n",
       "1     3              Uttar Pradesh  2,257,575  1,974,532   8.41%   \n",
       "2     5                    Gujarat          -  1,937,066   8.25%   \n",
       "3     7                  Rajasthan  1,413,620  1,218,193   5.19%   \n",
       "4     9             Andhra Pradesh  1,317,728  1,133,837   4.83%   \n",
       "5    11                     Kerala          -    932,470   3.97%   \n",
       "6    13                    Haryana    994,154    870,665   3.71%   \n",
       "7    15                      Bihar    751,396    650,302   2.77%   \n",
       "8    17                      Assam    493,167    412,612   1.76%   \n",
       "9    19                  Jharkhand    393,722    358,863   1.53%   \n",
       "10   21         Jammu & Kashmir-UT    227,927    199,917   0.85%   \n",
       "11   23                        Goa          -     82,604   0.35%   \n",
       "12   25                 Chandigarh          -     45,635   0.19%   \n",
       "13   27                  Meghalaya     42,697     38,785   0.17%   \n",
       "14   29                    Manipur          -     36,594   0.16%   \n",
       "15   31                   Nagaland          -     31,913   0.14%   \n",
       "16   33  Andaman & Nicobar Islands          -     10,371   0.04%   \n",
       "17    1                Maharashtra          -  2,690,525  13.24%   \n",
       "18    3                  Karnataka  2,036,748  1,782,121   8.77%   \n",
       "19    5                    Gujarat          -  1,700,504   8.37%   \n",
       "20    7                  Rajasthan  1,259,527  1,084,845   5.34%   \n",
       "21    9                  Telangana  1,187,082  1,024,205   5.04%   \n",
       "22   11                     Kerala          -    822,970   4.05%   \n",
       "23   13                    Haryana    885,308    779,197   3.83%   \n",
       "24   15                     Odisha    691,888    587,900   2.89%   \n",
       "25   17                      Assam    427,147    363,161   1.79%   \n",
       "26   19                  Jharkhand    360,689    325,830   1.60%   \n",
       "27   21         Jammu & Kashmir-UT    185,489    162,644   0.80%   \n",
       "28   23                        Goa          -     73,973   0.36%   \n",
       "29   25                 Chandigarh          -     40,573   0.20%   \n",
       "30   27                  Meghalaya     37,925     34,441   0.17%   \n",
       "31   29          Arunachal Pradesh          -     31,669   0.16%   \n",
       "32   31                   Nagaland          -     27,859   0.14%   \n",
       "33   33  Andaman & Nicobar Islands          -      9,209   0.05%   \n",
       "\n",
       "   GDP($ billion)  \n",
       "0         417.163  \n",
       "1         265.024  \n",
       "2         259.996  \n",
       "3         163.507  \n",
       "4         152.185  \n",
       "5         125.157  \n",
       "6         116.862  \n",
       "7          87.284  \n",
       "8          55.381  \n",
       "9          48.167  \n",
       "10         26.833  \n",
       "11         11.087  \n",
       "12          6.125  \n",
       "13          5.206  \n",
       "14          4.912  \n",
       "15          4.283  \n",
       "16          1.392  \n",
       "17              -  \n",
       "18      1,190,851  \n",
       "19              -  \n",
       "20        694,771  \n",
       "21        642,207  \n",
       "22              -  \n",
       "23        542,972  \n",
       "24        403,222  \n",
       "25        251,688  \n",
       "26        235,685  \n",
       "27        105,636  \n",
       "28              -  \n",
       "29              -  \n",
       "30         21,905  \n",
       "31              -  \n",
       "32              -  \n",
       "33              -  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = [] \n",
    "state = [] \n",
    "gsdp22 = []\n",
    "gsdp21 = []\n",
    "share = [] \n",
    "GDP = [] \n",
    "# Finding the table containing GDP details\n",
    "r_t=gdp.find_elements(By.XPATH,'//tr[@class=\"odd\"]/td[1]')\n",
    "for i in r_t:\n",
    "    try:\n",
    "        rank.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        rank.append('-')\n",
    "\n",
    "st=gdp.find_elements(By.XPATH,'//tr[@class=\"odd\"]/td[2]')\n",
    "for i in st:\n",
    "    try:\n",
    "        state.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        state.append('-')\n",
    "        \n",
    "gs22=gdp.find_elements(By.XPATH,'//tr[@class=\"odd\"]/td[3]')\n",
    "for i in gs22:\n",
    "    try:\n",
    "        gsdp22.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        gsdp22.append('-')\n",
    "\n",
    "gs21=gdp.find_elements(By.XPATH,'//tr[@class=\"odd\"]/td[4]')\n",
    "for i in gs21:\n",
    "    try:\n",
    "        gsdp21.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        gsdp21.append('-')\n",
    "        \n",
    "sh=gdp.find_elements(By.XPATH,'//tr[@class=\"odd\"]/td[5]')\n",
    "for i in sh:\n",
    "    try:\n",
    "        share.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        share.append('-')\n",
    "        \n",
    "gd=gdp.find_elements(By.XPATH,'//tr[@class=\"odd\"]/td[6]')\n",
    "for i in gd:\n",
    "    try:\n",
    "        GDP.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        GDP.append('-')\n",
    "        \n",
    "df_gdp=pd.DataFrame({\"Rank\":rank, \"State\":state, \"GSDP22-23\":gsdp22, \"GSDP21-22\":gsdp21, \"Share\":share,\"GDP($ billion)\":GDP})\n",
    "df_gdp# Creating a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda76629",
   "metadata": {},
   "source": [
    "##### 4. Scrape the details of trending repositories on Github.com.Url = https://github.com/You have to find the following details:A) Repository titleB) Repository descriptionC) Contributors countD) Language used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9d25615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "github=webdriver.Chrome()\n",
    "github.get('https://github.com/') # Initializing the WebDriver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2b9d847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab=github.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[1]/div[2]/button/span/span')\n",
    "tab.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c6a5af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ops=github.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "ops.click()\n",
    "t_b=github.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "t_b.click()# Open GitHub's trending page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ca9a7b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists to store data\n",
    "url=[]\n",
    "lang=[]\n",
    "count=[]\n",
    "\n",
    "# Extract details for each repository\n",
    "\n",
    "link=github.find_elements(By.XPATH,'//h2/a')\n",
    "for i in link:\n",
    "    url.append(i.get_attribute(\"href\"))\n",
    "    \n",
    "for i in url:\n",
    "    github.get(i)\n",
    "    try:\n",
    "        lan=github.find_element(By.XPATH,'//span[@class=\"color-fg-default text-bold mr-1\"]')\n",
    "        lang.append(lan.text)\n",
    "    except NoSuchElementException:\n",
    "        lang.append('-')\n",
    "        \n",
    "    try:\n",
    "        cc=github.find_element(By.XPATH,'//span[@class=\"Counter ml-1\"]')\n",
    "        count.append(cc.text)\n",
    "    except NoSuchElementException:\n",
    "        count.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e12a525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "rt=github.find_elements(By.XPATH,'//span[@class=\"text-normal\"]')\n",
    "for i in rt:\n",
    "    name.append(i.text)\n",
    "    \n",
    "des=[]\n",
    "dsc=github.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "for i in dsc:   \n",
    "    try:\n",
    "        des.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        des.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "bb7315e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Languages used</th>\n",
       "      <th>Contributors count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lobehub /</td>\n",
       "      <td>ü§ñ Lobe Chat - an open-source, high-performance...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chatchat-space /</td>\n",
       "      <td>Langchain-ChatchatÔºàÂéüLangchain-ChatGLMÔºâÂü∫‰∫é Langc...</td>\n",
       "      <td>Python</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>charlax /</td>\n",
       "      <td>A collection of learning resources for curious...</td>\n",
       "      <td>Python</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hiddify /</td>\n",
       "      <td>Multi-platform auto-proxy client, supporting S...</td>\n",
       "      <td>Dart</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>levihsu /</td>\n",
       "      <td>Official implementation of OOTDiffusion: Outfi...</td>\n",
       "      <td>Python</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Speykious /</td>\n",
       "      <td>Blazingly üî• fast üöÄ memory vulnerabilities, wri...</td>\n",
       "      <td>Rust</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>codecrafters-io /</td>\n",
       "      <td>Master programming by recreating your favorite...</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>systemdesign42 /</td>\n",
       "      <td>Building the best system design resource in th...</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weijunext /</td>\n",
       "      <td>Êî∂ÂΩïÁã¨Á´ãÂºÄÂèëËÄÖÂá∫Êµ∑ÊäÄÊúØÊ†àÂíåÂ∑•ÂÖ∑</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>qarmin /</td>\n",
       "      <td>Multi functional app to find duplicates, empty...</td>\n",
       "      <td>Rust</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>trimstray /</td>\n",
       "      <td>A collection of inspiring lists, manuals, chea...</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mttaggart /</td>\n",
       "      <td>Anxun Shanghai (I-SOON) Data Dump Translations...</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gunnarmorling /</td>\n",
       "      <td>1Ô∏è‚É£üêùüèéÔ∏è The One Billion Row Challenge -- A fun ...</td>\n",
       "      <td>Java</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vvbbnn00 /</td>\n",
       "      <td>ËØ•È°πÁõÆÂèØ‰ª•ËÆ©‰Ω†ÈÄöËøáËÆ¢ÈòÖÁöÑÊñπÂºè‰ΩøÁî®Cloudflare WARP+ÔºåËá™Âä®Ëé∑ÂèñÊµÅÈáè„ÄÇThis p...</td>\n",
       "      <td>Python</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>keras-team /</td>\n",
       "      <td>Deep Learning for humans</td>\n",
       "      <td>Python</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xtekky /</td>\n",
       "      <td>The official gpt4free repository | various col...</td>\n",
       "      <td>Python</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>charlax /</td>\n",
       "      <td>A collection of inspiring resources related to...</td>\n",
       "      <td>Shell</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>facebookresearch /</td>\n",
       "      <td>Official PyTorch Implementation of \"Scalable D...</td>\n",
       "      <td>Python</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>camunda /</td>\n",
       "      <td>Flexible framework for workflow and decision a...</td>\n",
       "      <td>Java</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>facebook /</td>\n",
       "      <td>A framework for building native applications u...</td>\n",
       "      <td>C++</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>krahets /</td>\n",
       "      <td>„ÄäHello ÁÆóÊ≥ï„ÄãÔºöÂä®ÁîªÂõæËß£„ÄÅ‰∏ÄÈîÆËøêË°åÁöÑÊï∞ÊçÆÁªìÊûÑ‰∏éÁÆóÊ≥ïÊïôÁ®ãÔºåÊîØÊåÅ Python, C++,...</td>\n",
       "      <td>Java</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ggerganov /</td>\n",
       "      <td>Port of Facebook's LLaMA model in C/C++</td>\n",
       "      <td>C++</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dunwu /</td>\n",
       "      <td>üêß LinuxÊïôÁ®ãÔºå‰∏ªË¶ÅÂÜÖÂÆπÔºöLinux ÂëΩ‰ª§„ÄÅLinux Á≥ªÁªüËøêÁª¥„ÄÅËΩØ‰ª∂ËøêÁª¥„ÄÅÁ≤æÈÄâÂ∏∏Áî®Sh...</td>\n",
       "      <td>Shell</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>maybe-finance /</td>\n",
       "      <td>The OS for your personal finances</td>\n",
       "      <td>Ruby</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Repository title                             Repository description  \\\n",
       "0            lobehub /  ü§ñ Lobe Chat - an open-source, high-performance...   \n",
       "1     chatchat-space /  Langchain-ChatchatÔºàÂéüLangchain-ChatGLMÔºâÂü∫‰∫é Langc...   \n",
       "2            charlax /  A collection of learning resources for curious...   \n",
       "3            hiddify /  Multi-platform auto-proxy client, supporting S...   \n",
       "4            levihsu /  Official implementation of OOTDiffusion: Outfi...   \n",
       "5          Speykious /  Blazingly üî• fast üöÄ memory vulnerabilities, wri...   \n",
       "6    codecrafters-io /  Master programming by recreating your favorite...   \n",
       "7     systemdesign42 /  Building the best system design resource in th...   \n",
       "8          weijunext /                                    Êî∂ÂΩïÁã¨Á´ãÂºÄÂèëËÄÖÂá∫Êµ∑ÊäÄÊúØÊ†àÂíåÂ∑•ÂÖ∑   \n",
       "9             qarmin /  Multi functional app to find duplicates, empty...   \n",
       "10         trimstray /  A collection of inspiring lists, manuals, chea...   \n",
       "11         mttaggart /  Anxun Shanghai (I-SOON) Data Dump Translations...   \n",
       "12     gunnarmorling /  1Ô∏è‚É£üêùüèéÔ∏è The One Billion Row Challenge -- A fun ...   \n",
       "13          vvbbnn00 /  ËØ•È°πÁõÆÂèØ‰ª•ËÆ©‰Ω†ÈÄöËøáËÆ¢ÈòÖÁöÑÊñπÂºè‰ΩøÁî®Cloudflare WARP+ÔºåËá™Âä®Ëé∑ÂèñÊµÅÈáè„ÄÇThis p...   \n",
       "14        keras-team /                           Deep Learning for humans   \n",
       "15            xtekky /  The official gpt4free repository | various col...   \n",
       "16           charlax /  A collection of inspiring resources related to...   \n",
       "17  facebookresearch /  Official PyTorch Implementation of \"Scalable D...   \n",
       "18           camunda /  Flexible framework for workflow and decision a...   \n",
       "19          facebook /  A framework for building native applications u...   \n",
       "20           krahets /  „ÄäHello ÁÆóÊ≥ï„ÄãÔºöÂä®ÁîªÂõæËß£„ÄÅ‰∏ÄÈîÆËøêË°åÁöÑÊï∞ÊçÆÁªìÊûÑ‰∏éÁÆóÊ≥ïÊïôÁ®ãÔºåÊîØÊåÅ Python, C++,...   \n",
       "21         ggerganov /            Port of Facebook's LLaMA model in C/C++   \n",
       "22             dunwu /  üêß LinuxÊïôÁ®ãÔºå‰∏ªË¶ÅÂÜÖÂÆπÔºöLinux ÂëΩ‰ª§„ÄÅLinux Á≥ªÁªüËøêÁª¥„ÄÅËΩØ‰ª∂ËøêÁª¥„ÄÅÁ≤æÈÄâÂ∏∏Áî®Sh...   \n",
       "23     maybe-finance /                  The OS for your personal finances   \n",
       "\n",
       "   Languages used Contributors count  \n",
       "0      TypeScript                 63  \n",
       "1          Python                     \n",
       "2          Python                 27  \n",
       "3            Dart                     \n",
       "4          Python                     \n",
       "5            Rust                     \n",
       "6               -                     \n",
       "7               -                     \n",
       "8               -                     \n",
       "9            Rust                 60  \n",
       "10              -                     \n",
       "11              -                     \n",
       "12           Java                     \n",
       "13         Python                  5  \n",
       "14         Python                     \n",
       "15         Python                179  \n",
       "16          Shell                     \n",
       "17         Python                  3  \n",
       "18           Java                     \n",
       "19            C++                     \n",
       "20           Java                141  \n",
       "21            C++                  1  \n",
       "22          Shell                     \n",
       "23           Ruby                     "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trending=pd.DataFrame({'Repository title':name,'Repository description':des,'Languages used':lang,'Contributors count':count})\n",
    "df_trending# Creating a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6574c5e",
   "metadata": {},
   "source": [
    "##### 5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the following details:A) Song nameB) Artist nameC) Last week rankD) Peak rankE) Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "cc190e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard=webdriver.Chrome()\n",
    "billboard.get('https:/www.billboard.com/') # Initializing the WebDriver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7b44af87",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag=billboard.find_element(By.XPATH,'/html/body/div[3]/header/div/div[4]/div/div[1]/div[1]/button')\n",
    "tag.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ccc340b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart=billboard.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3/button')\n",
    "chart.click()\n",
    "chart_b=billboard.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div/div/ul/li[1]/ul/li[2]/a')\n",
    "chart_b.click()# Navigate to the charts page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "62b7cd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lovin On Me</td>\n",
       "      <td>Jack Harlow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas Hold 'Em</td>\n",
       "      <td>Beyonce</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carnival</td>\n",
       "      <td>¬•$: Kanye West &amp; Ty Dolla $ign</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beautiful Things</td>\n",
       "      <td>Benson Boone</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lose Control</td>\n",
       "      <td>Teddy Swims</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Mmhmm</td>\n",
       "      <td>BigXthaPlug</td>\n",
       "      <td>83</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Monaco</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>77</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Prove It</td>\n",
       "      <td>21 Savage &amp; Summer Walker</td>\n",
       "      <td>75</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Perro Negro</td>\n",
       "      <td>Bad Bunny &amp; Feid</td>\n",
       "      <td>82</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Sunday Service</td>\n",
       "      <td>Latto</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Song Name                     Artist Name Last Week Rank Peak Rank  \\\n",
       "0        Lovin On Me                     Jack Harlow              1         1   \n",
       "1     Texas Hold 'Em                         Beyonce              -         2   \n",
       "2           Carnival  ¬•$: Kanye West & Ty Dolla $ign              -         3   \n",
       "3   Beautiful Things                    Benson Boone              3         3   \n",
       "4       Lose Control                     Teddy Swims              2         2   \n",
       "..               ...                             ...            ...       ...   \n",
       "95             Mmhmm                     BigXthaPlug             83        65   \n",
       "96            Monaco                       Bad Bunny             77         5   \n",
       "97          Prove It       21 Savage & Summer Walker             75        43   \n",
       "98       Perro Negro                Bad Bunny & Feid             82        20   \n",
       "99    Sunday Service                           Latto              -       100   \n",
       "\n",
       "   Weeks on Board  \n",
       "0              14  \n",
       "1               1  \n",
       "2               1  \n",
       "3               4  \n",
       "4              27  \n",
       "..            ...  \n",
       "95              8  \n",
       "96             18  \n",
       "97              5  \n",
       "98             15  \n",
       "99              1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating empty lists to store data\n",
    "name=[]\n",
    "artist=[]\n",
    "lwr=[]\n",
    "pr=[]\n",
    "wob=[]\n",
    "\n",
    "nm=billboard.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li/h3')\n",
    "for i in nm:\n",
    "    try:\n",
    "        name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        name.append('-')\n",
    "\n",
    "art=billboard.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[1]/span')\n",
    "for i in art:\n",
    "    try:\n",
    "        artist.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        artist.append('-')\n",
    "        \n",
    "l_rank=billboard.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[4]')\n",
    "for i in l_rank:\n",
    "    try:\n",
    "        lwr.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        lwr.append('-')\n",
    "        \n",
    "p_rank=billboard.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[5]')\n",
    "for i in p_rank:\n",
    "    try:\n",
    "        pr.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        pr.append('-')\n",
    "        \n",
    "wb=billboard.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[6]')\n",
    "for i in wb:\n",
    "    try:\n",
    "        wob.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        wob.append('-')\n",
    "\n",
    "df_100=pd.DataFrame({\"Song Name\":name,\"Artist Name\":artist,\"Last Week Rank\":lwr,\"Peak Rank\":pr,\"Weeks on Board\":wob})\n",
    "df_100# Creating a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad25b87c",
   "metadata": {},
   "source": [
    "##### 6. Scrape the details of Highest selling novels.A) Book nameB) Author nameC) Volumes soldD) PublisherE) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5f375782",
   "metadata": {},
   "outputs": [],
   "source": [
    "novels=webdriver.Chrome() # Initializing the WebDriver \n",
    "novels.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "679b74b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "      <td>Transworld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Children's Fiction</td>\n",
       "      <td>Bloomsbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Children's Fiction</td>\n",
       "      <td>Bloomsbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Children's Fiction</td>\n",
       "      <td>Bloomsbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "      <td>Random House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "      <td>Random House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "      <td>Penguin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Biography: General</td>\n",
       "      <td>Orion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "      <td>Penguin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold                    Publisher            Genre  \n",
       "0     5,094,805  Crime, Thriller & Adventure       Transworld  \n",
       "1     4,475,152           Children's Fiction       Bloomsbury  \n",
       "2     4,200,654           Children's Fiction       Bloomsbury  \n",
       "3     4,179,479           Children's Fiction       Bloomsbury  \n",
       "4     3,758,936              Romance & Sagas     Random House  \n",
       "..          ...                          ...              ...  \n",
       "95      807,311   General & Literary Fiction     Random House  \n",
       "96      794,201        Food & Drink: General          Penguin  \n",
       "97      792,187          Young Adult Fiction  Scholastic Ltd.  \n",
       "98      791,507           Biography: General            Orion  \n",
       "99      791,095        Food & Drink: General          Penguin  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating empty lists to store data\n",
    "b_name=[]\n",
    "a_name=[]\n",
    "vol=[]\n",
    "publisher=[]\n",
    "genre=[]\n",
    "\n",
    "nm=novels.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "for i in nm:\n",
    "    try:\n",
    "        b_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        b_name.append('-')\n",
    "\n",
    "anm=novels.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "for i in anm:\n",
    "    try:\n",
    "        a_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        a_name.append('-')\n",
    "vo=novels.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "for i in vo:\n",
    "    try:\n",
    "        vol.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vol.append('-')\n",
    "gn=novels.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "for i in gn:\n",
    "    try:\n",
    "        genre.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        genre.append('-')\n",
    "pub=novels.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "for i in pub:\n",
    "    try:\n",
    "        publisher.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        publisher.append('-')\n",
    "        \n",
    "df_novels=pd.DataFrame({'Book Name':b_name,'Author Name':a_name,'Volumes Sold':vol,\"Publisher\":publisher,'Genre':genre})\n",
    "df_novels# Creating a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e933f30",
   "metadata": {},
   "source": [
    "##### 7. Scrape the details most watched tv series of all time from imdb.com.Url = https://www.imdb.com/list/ls095964455/ You have to find the following details:A) NameB) Year spanC) GenreD) Run timeE) RatingsF) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "921a4b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb=webdriver.Chrome() # Initializing the WebDriver \n",
    "imdb.get('https://www.imdb.com/search/title/?title_type=tv_series&sort=num_votes,desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8e3c2f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists to store data\n",
    "url=[]\n",
    "genre=[]\n",
    "r_time=[]\n",
    "\n",
    "link=imdb.find_elements(By.XPATH,'//a[@class=\"ipc-title-link-wrapper\"]')\n",
    "for i in link:\n",
    "    url.append(i.get_attribute(\"href\"))\n",
    "    \n",
    "for i in url:\n",
    "    imdb.get(i)\n",
    "    try:\n",
    "        run=imdb.find_element(By.XPATH,'//div[@class=\"sc-69e49b85-0 jqlHBQ\"]/ul/li[4]')\n",
    "        r_time.append(run.text)\n",
    "    except NoSuchElementException:\n",
    "        r_time.append('-')\n",
    "        \n",
    "    try:\n",
    "        gen=imdb.find_element(By.XPATH,'//div[@class=\"ipc-chip-list--baseAlt ipc-chip-list\"]')\n",
    "        genre.append(gen.text)\n",
    "    except NoSuchElementException:\n",
    "        genre.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6dea0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "year=[]\n",
    "votes=[]\n",
    "ratings=[]\n",
    "\n",
    "nm=imdb.find_elements(By.XPATH,'//div[@class=\"sc-be6f1408-0 gVGktK\"]/div/a/h3')\n",
    "for i in nm:\n",
    "    name.append(i.text)\n",
    "\n",
    "ye=imdb.find_elements(By.XPATH,'//div[@class=\"sc-be6f1408-0 gVGktK\"]/div[2]/span[1]')\n",
    "for i in ye:\n",
    "    year.append(i.text)\n",
    "\n",
    "ra=imdb.find_elements(By.XPATH,'//div[@class=\"sc-be6f1408-0 gVGktK\"]/span/div/span')\n",
    "for i in ra:\n",
    "    ratings.append(i.text)\n",
    "\n",
    "vo=imdb.find_elements(By.XPATH,'//div[@class=\"sc-f24f1c5c-0 cPpOqU\"]')\n",
    "for i in vo:\n",
    "    votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "42444571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Game of Thrones</td>\n",
       "      <td>2011‚Äì2019</td>\n",
       "      <td>Action,Adventure,Drama</td>\n",
       "      <td>55m</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,259,175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Breaking Bad</td>\n",
       "      <td>2008‚Äì2013</td>\n",
       "      <td>Crime,Drama,Thriller</td>\n",
       "      <td>45m</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2,106,604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. Stranger Things</td>\n",
       "      <td>2016‚Äì2025</td>\n",
       "      <td>Drama,Fantasy,Horror</td>\n",
       "      <td>51m</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,318,050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. Friends</td>\n",
       "      <td>1994‚Äì2004</td>\n",
       "      <td>Comedy,Romance</td>\n",
       "      <td>88h</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1,077,381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. The Walking Dead</td>\n",
       "      <td>2010‚Äì2022</td>\n",
       "      <td>Drama,Horror,Thriller</td>\n",
       "      <td>44m</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,070,382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6. Sherlock</td>\n",
       "      <td>2010‚Äì2017</td>\n",
       "      <td>Crime,Drama,Mystery</td>\n",
       "      <td>1h 28m</td>\n",
       "      <td>9.1</td>\n",
       "      <td>988,312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7. The Big Bang Theory</td>\n",
       "      <td>2007‚Äì2019</td>\n",
       "      <td>Comedy,Romance</td>\n",
       "      <td>95h 2m</td>\n",
       "      <td>8.1</td>\n",
       "      <td>860,084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8. Dexter</td>\n",
       "      <td>2006‚Äì2013</td>\n",
       "      <td>Crime,Drama,Mystery</td>\n",
       "      <td>55m</td>\n",
       "      <td>8.7</td>\n",
       "      <td>758,853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9. How I Met Your Mother</td>\n",
       "      <td>2005‚Äì2014</td>\n",
       "      <td>Comedy,Drama,Romance</td>\n",
       "      <td>76h 16m</td>\n",
       "      <td>8.3</td>\n",
       "      <td>723,370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10. The Office</td>\n",
       "      <td>2005‚Äì2013</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>22m</td>\n",
       "      <td>9.0</td>\n",
       "      <td>698,507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11. True Detective</td>\n",
       "      <td>2014‚Äì</td>\n",
       "      <td>Crime,Drama,Mystery</td>\n",
       "      <td>55m</td>\n",
       "      <td>8.9</td>\n",
       "      <td>641,307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12. Peaky Blinders</td>\n",
       "      <td>2013‚Äì2022</td>\n",
       "      <td>Crime,Drama</td>\n",
       "      <td>35h 9m</td>\n",
       "      <td>8.8</td>\n",
       "      <td>636,278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13. Better Call Saul</td>\n",
       "      <td>2015‚Äì2022</td>\n",
       "      <td>Crime,Drama</td>\n",
       "      <td>52h 34m</td>\n",
       "      <td>9.0</td>\n",
       "      <td>635,427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14. The Boys</td>\n",
       "      <td>2019‚Äì</td>\n",
       "      <td>Action,Comedy,Crime</td>\n",
       "      <td>1h</td>\n",
       "      <td>8.7</td>\n",
       "      <td>633,479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15. Black Mirror</td>\n",
       "      <td>2011‚Äì</td>\n",
       "      <td>Drama,Mystery,Sci-Fi</td>\n",
       "      <td>1h</td>\n",
       "      <td>8.7</td>\n",
       "      <td>632,277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16. Rick and Morty</td>\n",
       "      <td>2013‚Äì</td>\n",
       "      <td>Animation,Adventure,Comedy</td>\n",
       "      <td>23m</td>\n",
       "      <td>9.1</td>\n",
       "      <td>593,698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17. Lost</td>\n",
       "      <td>2004‚Äì2010</td>\n",
       "      <td>Adventure,Drama,Fantasy</td>\n",
       "      <td>90h 45m</td>\n",
       "      <td>8.3</td>\n",
       "      <td>589,687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18. The Mandalorian</td>\n",
       "      <td>2019‚Äì</td>\n",
       "      <td>Action,Adventure,Fantasy</td>\n",
       "      <td>40m</td>\n",
       "      <td>8.7</td>\n",
       "      <td>579,606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19. Vikings</td>\n",
       "      <td>2013‚Äì2020</td>\n",
       "      <td>Action,Adventure,Drama</td>\n",
       "      <td>44m</td>\n",
       "      <td>8.5</td>\n",
       "      <td>575,250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20. Prison Break</td>\n",
       "      <td>2005‚Äì2017</td>\n",
       "      <td>Action,Crime,Drama</td>\n",
       "      <td>44m</td>\n",
       "      <td>8.3</td>\n",
       "      <td>574,316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21. The Witcher</td>\n",
       "      <td>2019‚Äì</td>\n",
       "      <td>Action,Adventure,Drama</td>\n",
       "      <td>1h</td>\n",
       "      <td>8.0</td>\n",
       "      <td>564,541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22. Squid Game</td>\n",
       "      <td>2021‚Äì</td>\n",
       "      <td>Action,Drama,Mystery</td>\n",
       "      <td>55m</td>\n",
       "      <td>8.0</td>\n",
       "      <td>530,345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23. Westworld</td>\n",
       "      <td>2016‚Äì2022</td>\n",
       "      <td>Drama,Mystery,Sci-Fi</td>\n",
       "      <td>1h 2m</td>\n",
       "      <td>8.5</td>\n",
       "      <td>529,258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24. House of Cards</td>\n",
       "      <td>2013‚Äì2018</td>\n",
       "      <td>Drama</td>\n",
       "      <td>63h 24m</td>\n",
       "      <td>8.6</td>\n",
       "      <td>527,928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25. Money Heist</td>\n",
       "      <td>2017‚Äì2021</td>\n",
       "      <td>Action,Crime,Drama</td>\n",
       "      <td>1h 10m</td>\n",
       "      <td>8.2</td>\n",
       "      <td>525,916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26. House</td>\n",
       "      <td>2004‚Äì2012</td>\n",
       "      <td>Drama,Mystery</td>\n",
       "      <td>129h 48m</td>\n",
       "      <td>8.7</td>\n",
       "      <td>504,130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27. The Last of Us</td>\n",
       "      <td>2023‚Äì</td>\n",
       "      <td>Action,Adventure,Drama</td>\n",
       "      <td>50m</td>\n",
       "      <td>8.8</td>\n",
       "      <td>500,798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28. Attack on Titan</td>\n",
       "      <td>2013‚Äì2023</td>\n",
       "      <td>Animation,Action,Adventure</td>\n",
       "      <td>24m</td>\n",
       "      <td>9.1</td>\n",
       "      <td>497,628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29. Supernatural</td>\n",
       "      <td>2005‚Äì2020</td>\n",
       "      <td>Drama,Fantasy,Horror</td>\n",
       "      <td>44m</td>\n",
       "      <td>8.4</td>\n",
       "      <td>478,497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30. Modern Family</td>\n",
       "      <td>2009‚Äì2020</td>\n",
       "      <td>Comedy,Drama,Romance</td>\n",
       "      <td>89h 38m</td>\n",
       "      <td>8.5</td>\n",
       "      <td>476,404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31. Suits</td>\n",
       "      <td>2011‚Äì2019</td>\n",
       "      <td>Comedy,Drama</td>\n",
       "      <td>44m</td>\n",
       "      <td>8.4</td>\n",
       "      <td>471,258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32. Daredevil</td>\n",
       "      <td>2015‚Äì2018</td>\n",
       "      <td>Action,Crime,Drama</td>\n",
       "      <td>54m</td>\n",
       "      <td>8.6</td>\n",
       "      <td>470,828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33. Narcos</td>\n",
       "      <td>2015‚Äì2017</td>\n",
       "      <td>Biography,Crime,Drama</td>\n",
       "      <td>49m</td>\n",
       "      <td>8.8</td>\n",
       "      <td>465,096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34. The Sopranos</td>\n",
       "      <td>1999‚Äì2007</td>\n",
       "      <td>Crime,Drama</td>\n",
       "      <td>55m</td>\n",
       "      <td>9.2</td>\n",
       "      <td>461,844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35. Arrow</td>\n",
       "      <td>2012‚Äì2020</td>\n",
       "      <td>Action,Adventure,Crime</td>\n",
       "      <td>42m</td>\n",
       "      <td>7.5</td>\n",
       "      <td>444,573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36. Dark</td>\n",
       "      <td>2017‚Äì2020</td>\n",
       "      <td>Crime,Drama,Mystery</td>\n",
       "      <td>24h 15m</td>\n",
       "      <td>8.7</td>\n",
       "      <td>437,023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37. The Simpsons</td>\n",
       "      <td>1989‚Äì</td>\n",
       "      <td>Animation,Comedy</td>\n",
       "      <td>22m</td>\n",
       "      <td>8.7</td>\n",
       "      <td>432,663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38. Fargo</td>\n",
       "      <td>2014‚Äì2024</td>\n",
       "      <td>Crime,Drama,Thriller</td>\n",
       "      <td>53m</td>\n",
       "      <td>8.9</td>\n",
       "      <td>415,543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39. Mr. Robot</td>\n",
       "      <td>2015‚Äì2019</td>\n",
       "      <td>Crime,Drama,Thriller</td>\n",
       "      <td>49m</td>\n",
       "      <td>8.5</td>\n",
       "      <td>414,783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40. Loki</td>\n",
       "      <td>2021‚Äì2023</td>\n",
       "      <td>Action,Adventure,Fantasy</td>\n",
       "      <td>9h 46m</td>\n",
       "      <td>8.2</td>\n",
       "      <td>406,010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41. South Park</td>\n",
       "      <td>1997‚Äì</td>\n",
       "      <td>Animation,Comedy</td>\n",
       "      <td>22m</td>\n",
       "      <td>8.7</td>\n",
       "      <td>403,021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42. The Wire</td>\n",
       "      <td>2002‚Äì2008</td>\n",
       "      <td>Crime,Drama,Thriller</td>\n",
       "      <td>59m</td>\n",
       "      <td>9.3</td>\n",
       "      <td>372,554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43. Death Note</td>\n",
       "      <td>2006‚Äì2007</td>\n",
       "      <td>Animation,Crime,Drama</td>\n",
       "      <td>24m</td>\n",
       "      <td>8.9</td>\n",
       "      <td>371,989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44. The Flash</td>\n",
       "      <td>2014‚Äì2023</td>\n",
       "      <td>Action,Adventure,Drama</td>\n",
       "      <td>43m</td>\n",
       "      <td>7.5</td>\n",
       "      <td>366,737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45. House of the Dragon</td>\n",
       "      <td>2022‚Äì</td>\n",
       "      <td>Action,Adventure,Drama</td>\n",
       "      <td>50m</td>\n",
       "      <td>8.4</td>\n",
       "      <td>362,991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46. Family Guy</td>\n",
       "      <td>1999‚Äì2025</td>\n",
       "      <td>Animation,Comedy</td>\n",
       "      <td>22m</td>\n",
       "      <td>8.2</td>\n",
       "      <td>361,665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47. Homeland</td>\n",
       "      <td>2011‚Äì2020</td>\n",
       "      <td>Crime,Drama,Mystery</td>\n",
       "      <td>55m</td>\n",
       "      <td>8.3</td>\n",
       "      <td>359,032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48. Avatar: The Last Airbender</td>\n",
       "      <td>2005‚Äì2008</td>\n",
       "      <td>Animation,Action,Adventure</td>\n",
       "      <td>23m</td>\n",
       "      <td>9.3</td>\n",
       "      <td>356,940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49. Brooklyn Nine-Nine</td>\n",
       "      <td>2013‚Äì2021</td>\n",
       "      <td>Comedy,Crime</td>\n",
       "      <td>22m</td>\n",
       "      <td>8.4</td>\n",
       "      <td>355,645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50. Wednesday</td>\n",
       "      <td>2022‚Äì</td>\n",
       "      <td>Comedy,Crime,Fantasy</td>\n",
       "      <td>45m</td>\n",
       "      <td>8.1</td>\n",
       "      <td>352,610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name  Year Span                       Genre  \\\n",
       "0               1. Game of Thrones  2011‚Äì2019      Action,Adventure,Drama   \n",
       "1                  2. Breaking Bad  2008‚Äì2013        Crime,Drama,Thriller   \n",
       "2               3. Stranger Things  2016‚Äì2025        Drama,Fantasy,Horror   \n",
       "3                       4. Friends  1994‚Äì2004              Comedy,Romance   \n",
       "4              5. The Walking Dead  2010‚Äì2022       Drama,Horror,Thriller   \n",
       "5                      6. Sherlock  2010‚Äì2017         Crime,Drama,Mystery   \n",
       "6           7. The Big Bang Theory  2007‚Äì2019              Comedy,Romance   \n",
       "7                        8. Dexter  2006‚Äì2013         Crime,Drama,Mystery   \n",
       "8         9. How I Met Your Mother  2005‚Äì2014        Comedy,Drama,Romance   \n",
       "9                   10. The Office  2005‚Äì2013                      Comedy   \n",
       "10              11. True Detective      2014‚Äì         Crime,Drama,Mystery   \n",
       "11              12. Peaky Blinders  2013‚Äì2022                 Crime,Drama   \n",
       "12            13. Better Call Saul  2015‚Äì2022                 Crime,Drama   \n",
       "13                    14. The Boys      2019‚Äì         Action,Comedy,Crime   \n",
       "14                15. Black Mirror      2011‚Äì        Drama,Mystery,Sci-Fi   \n",
       "15              16. Rick and Morty      2013‚Äì  Animation,Adventure,Comedy   \n",
       "16                        17. Lost  2004‚Äì2010     Adventure,Drama,Fantasy   \n",
       "17             18. The Mandalorian      2019‚Äì    Action,Adventure,Fantasy   \n",
       "18                     19. Vikings  2013‚Äì2020      Action,Adventure,Drama   \n",
       "19                20. Prison Break  2005‚Äì2017          Action,Crime,Drama   \n",
       "20                 21. The Witcher      2019‚Äì      Action,Adventure,Drama   \n",
       "21                  22. Squid Game      2021‚Äì        Action,Drama,Mystery   \n",
       "22                   23. Westworld  2016‚Äì2022        Drama,Mystery,Sci-Fi   \n",
       "23              24. House of Cards  2013‚Äì2018                       Drama   \n",
       "24                 25. Money Heist  2017‚Äì2021          Action,Crime,Drama   \n",
       "25                       26. House  2004‚Äì2012               Drama,Mystery   \n",
       "26              27. The Last of Us      2023‚Äì      Action,Adventure,Drama   \n",
       "27             28. Attack on Titan  2013‚Äì2023  Animation,Action,Adventure   \n",
       "28                29. Supernatural  2005‚Äì2020        Drama,Fantasy,Horror   \n",
       "29               30. Modern Family  2009‚Äì2020        Comedy,Drama,Romance   \n",
       "30                       31. Suits  2011‚Äì2019                Comedy,Drama   \n",
       "31                   32. Daredevil  2015‚Äì2018          Action,Crime,Drama   \n",
       "32                      33. Narcos  2015‚Äì2017       Biography,Crime,Drama   \n",
       "33                34. The Sopranos  1999‚Äì2007                 Crime,Drama   \n",
       "34                       35. Arrow  2012‚Äì2020      Action,Adventure,Crime   \n",
       "35                        36. Dark  2017‚Äì2020         Crime,Drama,Mystery   \n",
       "36                37. The Simpsons      1989‚Äì            Animation,Comedy   \n",
       "37                       38. Fargo  2014‚Äì2024        Crime,Drama,Thriller   \n",
       "38                   39. Mr. Robot  2015‚Äì2019        Crime,Drama,Thriller   \n",
       "39                        40. Loki  2021‚Äì2023    Action,Adventure,Fantasy   \n",
       "40                  41. South Park      1997‚Äì            Animation,Comedy   \n",
       "41                    42. The Wire  2002‚Äì2008        Crime,Drama,Thriller   \n",
       "42                  43. Death Note  2006‚Äì2007       Animation,Crime,Drama   \n",
       "43                   44. The Flash  2014‚Äì2023      Action,Adventure,Drama   \n",
       "44         45. House of the Dragon      2022‚Äì      Action,Adventure,Drama   \n",
       "45                  46. Family Guy  1999‚Äì2025            Animation,Comedy   \n",
       "46                    47. Homeland  2011‚Äì2020         Crime,Drama,Mystery   \n",
       "47  48. Avatar: The Last Airbender  2005‚Äì2008  Animation,Action,Adventure   \n",
       "48          49. Brooklyn Nine-Nine  2013‚Äì2021                Comedy,Crime   \n",
       "49                   50. Wednesday      2022‚Äì        Comedy,Crime,Fantasy   \n",
       "\n",
       "    Run Time Ratings       Votes  \n",
       "0        55m     9.2   2,259,175  \n",
       "1        45m     9.5   2,106,604  \n",
       "2        51m     8.7   1,318,050  \n",
       "3        88h     8.9   1,077,381  \n",
       "4        44m     8.1   1,070,382  \n",
       "5     1h 28m     9.1     988,312  \n",
       "6     95h 2m     8.1     860,084  \n",
       "7        55m     8.7     758,853  \n",
       "8    76h 16m     8.3     723,370  \n",
       "9        22m     9.0     698,507  \n",
       "10       55m     8.9     641,307  \n",
       "11    35h 9m     8.8     636,278  \n",
       "12   52h 34m     9.0     635,427  \n",
       "13        1h     8.7     633,479  \n",
       "14        1h     8.7     632,277  \n",
       "15       23m     9.1     593,698  \n",
       "16   90h 45m     8.3     589,687  \n",
       "17       40m     8.7     579,606  \n",
       "18       44m     8.5     575,250  \n",
       "19       44m     8.3     574,316  \n",
       "20        1h     8.0     564,541  \n",
       "21       55m     8.0     530,345  \n",
       "22     1h 2m     8.5     529,258  \n",
       "23   63h 24m     8.6     527,928  \n",
       "24    1h 10m     8.2     525,916  \n",
       "25  129h 48m     8.7     504,130  \n",
       "26       50m     8.8     500,798  \n",
       "27       24m     9.1     497,628  \n",
       "28       44m     8.4     478,497  \n",
       "29   89h 38m     8.5     476,404  \n",
       "30       44m     8.4     471,258  \n",
       "31       54m     8.6     470,828  \n",
       "32       49m     8.8     465,096  \n",
       "33       55m     9.2     461,844  \n",
       "34       42m     7.5     444,573  \n",
       "35   24h 15m     8.7     437,023  \n",
       "36       22m     8.7     432,663  \n",
       "37       53m     8.9     415,543  \n",
       "38       49m     8.5     414,783  \n",
       "39    9h 46m     8.2     406,010  \n",
       "40       22m     8.7     403,021  \n",
       "41       59m     9.3     372,554  \n",
       "42       24m     8.9     371,989  \n",
       "43       43m     7.5     366,737  \n",
       "44       50m     8.4     362,991  \n",
       "45       22m     8.2     361,665  \n",
       "46       55m     8.3     359,032  \n",
       "47       23m     9.3     356,940  \n",
       "48       22m     8.4     355,645  \n",
       "49       45m     8.1     352,610  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Name':name,'Year Span':year,'Genre':genre,'Run Time':r_time,'Ratings':ratings,'Votes':votes})\n",
    "df['Genre'] = df['Genre'].str.replace('\\n', ',')\n",
    "df['Votes'] = df['Votes'].str.replace(r'Votes', ' ')\n",
    "df['Ratings'] = df['Ratings'].str.replace('\\n(.*)', '')\n",
    "df# Creating a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fa1f2e",
   "metadata": {},
   "source": [
    "##### 8. Details of Datasets from UCI machine learning repositories.Url = https://archive.ics.uci.edu/ You have to find the following details:A) Dataset nameB) Data typeC) TaskD) Attribute typeE) No of instancesF) No of attribute G) Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c373bb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "uci=webdriver.Chrome()\n",
    "uci.get('https://archive.ics.uci.edu/') # Initializing the WebDriver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b326f2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "select=uci.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/section[1]/div[2]/a')\n",
    "select.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "a61a33f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists to store data\n",
    "urls=[]\n",
    "dt=[]\n",
    "tsk=[]\n",
    "at=[]\n",
    "noi=[]\n",
    "noa=[]\n",
    "year=[]\n",
    "\n",
    "link=uci.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "for i in link:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "    \n",
    "for i in urls:\n",
    "    uci.get(i)\n",
    "    try:\n",
    "        data=uci.find_element(By.XPATH,'(//p[@class=\"text-md\"])[1]')\n",
    "        dt.append(data.text)\n",
    "    except NoSuchElementException:\n",
    "        dt.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        tk=uci.find_element(By.XPATH,'(//p[@class=\"text-md\"])[3]')\n",
    "        tsk.append(tk.text)\n",
    "    except NoSuchElementException:\n",
    "        tsk.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        att=uci.find_element(By.XPATH,'(//p[@class=\"text-md\"])[4]')\n",
    "        at.append(att.text)\n",
    "    except NoSuchElementException:\n",
    "        at.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        ins=uci.find_element(By.XPATH,'(//p[@class=\"text-md\"])[5]')\n",
    "        noi.append(ins.text)\n",
    "    except NoSuchElementException:\n",
    "        noi.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        na=uci.find_element(By.XPATH,'(//p[@class=\"text-md\"])[6]')\n",
    "        noa.append(na.text)\n",
    "    except NoSuchElementException:\n",
    "        noa.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        yr=uci.find_element(By.XPATH,'//h2[@class=\"text-sm text-primary-content\"]')\n",
    "        year.append(yr.text)\n",
    "    except NoSuchElementException:\n",
    "        year.append(\"-\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "5999488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "dn=uci.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "for i in dn:\n",
    "    name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "55784c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>Instances</th>\n",
       "      <th>Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>Donated on 6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13611</td>\n",
       "      <td>16</td>\n",
       "      <td>Donated on 9/13/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>13</td>\n",
       "      <td>Donated on 6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3810</td>\n",
       "      <td>7</td>\n",
       "      <td>Donated on 10/5/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>Donated on 4/30/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Raisin</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real, Integer</td>\n",
       "      <td>900</td>\n",
       "      <td>7</td>\n",
       "      <td>Donated on 8/13/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178</td>\n",
       "      <td>13</td>\n",
       "      <td>Donated on 6/30/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>30</td>\n",
       "      <td>Donated on 10/31/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4898</td>\n",
       "      <td>11</td>\n",
       "      <td>Donated on 10/6/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dataset Name                  Data Type  \\\n",
       "0                                  Iris                    Tabular   \n",
       "1                      Dry Bean Dataset               Multivariate   \n",
       "2                         Heart Disease               Multivariate   \n",
       "3            Rice (Cammeo and Osmancik)               Multivariate   \n",
       "4                                 Adult               Multivariate   \n",
       "5                                Raisin               Multivariate   \n",
       "6                                  Wine                    Tabular   \n",
       "7  Breast Cancer Wisconsin (Diagnostic)               Multivariate   \n",
       "8                          Wine Quality               Multivariate   \n",
       "9                              Diabetes  Multivariate, Time-Series   \n",
       "\n",
       "                         Task              Attribute Type Instances  \\\n",
       "0              Classification                        Real       150   \n",
       "1              Classification               Integer, Real     13611   \n",
       "2              Classification  Categorical, Integer, Real       303   \n",
       "3              Classification                        Real      3810   \n",
       "4              Classification        Categorical, Integer     48842   \n",
       "5              Classification               Real, Integer       900   \n",
       "6              Classification               Integer, Real       178   \n",
       "7              Classification                        Real       569   \n",
       "8  Classification, Regression                        Real      4898   \n",
       "9              Classification        Categorical, Integer         1   \n",
       "\n",
       "  Attributes                   Year  \n",
       "0          4   Donated on 6/30/1988  \n",
       "1         16   Donated on 9/13/2020  \n",
       "2         13   Donated on 6/30/1988  \n",
       "3          7   Donated on 10/5/2019  \n",
       "4         14   Donated on 4/30/1996  \n",
       "5          7   Donated on 8/13/2023  \n",
       "6         13   Donated on 6/30/1991  \n",
       "7         30  Donated on 10/31/1995  \n",
       "8         11   Donated on 10/6/2009  \n",
       "9         20                      -  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uci=pd.DataFrame({\"Dataset Name\":name,\"Data Type\":dt,\"Task\":tsk,\"Attribute Type\":at,\"Instances\":noi,\"Attributes\":noa,\"Year\":year})\n",
    "df_uci# Creating a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479e45f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
